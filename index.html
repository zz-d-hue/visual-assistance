<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>视觉障碍辅助识别与语音播报</title>
    <style>
      :root {
        color-scheme: light dark;
      }
      body {
        margin: 0;
        font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica,
          Arial, "PingFang SC", "Noto Sans CJK", "Microsoft YaHei", sans-serif;
        background: #111;
        color: #eaeaea;
      }
      header {
        padding: 16px;
        border-bottom: 1px solid #333;
        display: flex;
        gap: 12px;
        align-items: center;
        flex-wrap: wrap;
      }
      main {
        display: grid;
        place-items: center;
        padding: 16px;
      }
      .controls {
        display: flex;
        gap: 12px;
        align-items: center;
        flex-wrap: wrap;
      }
      button,
      select,
      label {
        font-size: 16px;
        padding: 10px 14px;
        border-radius: 8px;
        border: 1px solid #444;
        background: #1b1b1b;
        color: #eaeaea;
      }
      button {
        cursor: pointer;
      }
      button:disabled {
        opacity: 0.6;
        cursor: not-allowed;
      }
      #stage {
        position: relative;
        max-width: 92vw;
      }
      #video {
        width: 100%;
        height: auto;
        display: block;
        filter: brightness(1.35) contrast(1.15) saturate(1.05);
      }
      #canvas {
        position: absolute;
        inset: 0;
        width: 100%;
        height: 100%;
        background: transparent;
        border-radius: 8px;
      }
      .badge {
        position: fixed;
        bottom: 10px;
        right: 10px;
        font-size: 12px;
        color: #888;
      }
    </style>
    <script
      crossorigin
      src="https://unpkg.com/react@18/umd/react.production.min.js"
    ></script>
    <script
      crossorigin
      src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"
    ></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
  </head>
  <body>
    <header>
      <div class="controls" role="group" aria-label="控制面板">
        <button id="startBtn" aria-label="开始识别">开始识别</button>
        <button id="stopBtn" aria-label="停止识别" disabled>停止识别</button>
        <label>
          <input
            type="checkbox"
            id="speakToggle"
            aria-label="开启语音播报"
            checked
          />
          语音播报
        </label>
        <label>
          识别频率
          <select id="fpsSelect" aria-label="识别频率">
            <option value="2">每秒2次</option>
            <option value="4" selected>每秒4次</option>
            <option value="8">每秒8次</option>
          </select>
        </label>
        <label>
          识别方式
          <select id="modeSelect" aria-label="识别方式">
            <option value="local">本地优先</option>
            <option value="server">服务端优先</option>
            <option value="parallel" selected>并行识别</option>
          </select>
        </label>
      </div>
    </header>
    <main>
      <div id="stage" aria-label="视频与标注区域">
        <video id="video" playsinline autoplay muted></video>
        <canvas id="canvas"></canvas>
      </div>
    </main>
    <div class="badge" id="badge">
      状态：未开始 · 服务端大模型识别 · 纯 HTML/JS 前端
    </div>
    <script>
      function loadScript(src) {
        return new Promise((resolve, reject) => {
          const s = document.createElement("script");
          s.src = src;
          s.async = true;
          s.onload = resolve;
          s.onerror = reject;
          document.head.appendChild(s);
        });
      }
      const TFJS_URL =
        "https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.16.0/dist/tf.min.js";
      const COCO_URL =
        "https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js";
      async function ensureCoco() {
        if (!window.tf) await loadScript(TFJS_URL);
        if (!window.cocoSsd) await loadScript(COCO_URL);
      }
      async function ensureVideoReady(videoEl) {
        for (let i = 0; i < 60; i++) {
          if (
            videoEl.readyState >= 2 &&
            videoEl.videoWidth &&
            videoEl.videoHeight
          )
            return;
          await new Promise((r) => requestAnimationFrame(r));
        }
      }
      const video = document.getElementById("video");
      const canvas = document.getElementById("canvas");
      const ctx = canvas.getContext("2d");
      const captureCanvas = document.createElement("canvas");
      const captureCtx = captureCanvas.getContext("2d");
      const startBtn = document.getElementById("startBtn");
      const stopBtn = document.getElementById("stopBtn");
      const speakToggle = document.getElementById("speakToggle");
      const fpsSelect = document.getElementById("fpsSelect");
      const modeSelect = document.getElementById("modeSelect");
      const badge = document.getElementById("badge");

      let running = false;
      let speakOn = true;
      let fps = 4;
      let model = null;
      let status = "未开始";
      let mode = "parallel";
      const spokenMap = new Map();
      let raf = null;
      let lastMs = 0;
      let imageCapture = null;
      const apiEndpoint = "/api/vision/detect";
      const cooldownMs = 4000;
      let lastDets = [];

      function setStatus(next) {
        status = next;
        badge.textContent = `状态：${status} · 服务端大模型识别 · 纯 HTML/JS 前端`;
      }
      function setRunning(next) {
        running = next;
        startBtn.disabled = running;
        stopBtn.disabled = !running;
      }
      function drawOverlay(detections) {
        ctx.lineWidth = 3;
        const labels = new Set();
        for (const det of detections) {
          const [x, y, w, h] = det.bbox;
          const label = det.label || det.class || "物体";
          labels.add(label);
          ctx.strokeStyle = "rgba(0, 200, 255, 0.9)";
          ctx.fillStyle = "rgba(0, 200, 255, 0.18)";
          ctx.strokeRect(x, y, w, h);
          ctx.fillRect(x, y, w, h);
          ctx.fillStyle = "rgba(0, 0, 0, 0.65)";
          ctx.fillRect(x, y - 28, ctx.measureText(label).width + 16, 24);
          ctx.fillStyle = "#00e0ff";
          ctx.font = "18px system-ui";
          ctx.fillText(label, x + 8, y - 10);
        }
        const text = `识别：${detections.length} · ${Array.from(labels).join(
          "、"
        )}`;
        ctx.fillStyle = "rgba(0, 0, 0, 0.65)";
        const tw = ctx.measureText(text).width + 16;
        ctx.fillRect(8, 8, tw, 26);
        ctx.fillStyle = "#00e0ff";
        ctx.font = "16px system-ui";
        ctx.fillText(text, 16, 26);
      }
      function speakDetections(detections, source) {
        if (!speakOn) return;
        if (mode === "server" && source !== "server") return;
        const now = performance.now();
        const labels = new Set();
        for (const det of detections) {
          if (det.score < 0.3) continue;
          const label = det.label || det.class || "物体";
          labels.add(label);
        }
        for (const label of labels) {
          const last = spokenMap.get(label) || 0;
          if (now - last > cooldownMs) {
            const utter = new SpeechSynthesisUtterance(label);
            utter.lang = "zh-CN";
            utter.rate = 1;
            speechSynthesis.speak(utter);
            spokenMap.set(label, now);
          }
        }
      }
      async function detectServer() {
        console.log("[detectServer] start POST", apiEndpoint);
        captureCtx.filter = "brightness(1.35) contrast(1.15) saturate(1.05)";
        captureCtx.drawImage(
          video,
          0,
          0,
          captureCanvas.width,
          captureCanvas.height
        );
        const dataUrl = captureCanvas.toDataURL("image/jpeg", 0.95);
        const body = {
          image: dataUrl,
          width: canvas.width,
          height: canvas.height,
        };
        const resp = await fetch(apiEndpoint, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(body),
        });
        console.log("[detectServer] response status", resp.status);
        if (!resp.ok) {
          const text = await resp.text().catch(() => "");
          console.error("[detectServer] upstream error", text);
          throw new Error(text || "server error");
        }
        const json = await resp.json();
        console.log("[detectServer] response json", json);
        return json.detections || [];
      }
      async function drawFrame() {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        if (video.readyState < 2 && imageCapture) {
          try {
            const bitmap = await imageCapture.grabFrame();
            // 仅用于确保视频流活跃，无需绘制到叠加层
            if (bitmap.close) bitmap.close();
          } catch {}
        }
        const info = `video rs=${video.readyState} ${video.videoWidth}x${video.videoHeight}`;
        ctx.fillStyle = "rgba(0,0,0,0.5)";
        const tw = ctx.measureText(info).width + 16;
        ctx.fillRect(canvas.width - tw - 8, 8, tw, 22);
        ctx.fillStyle = "#ccc";
        ctx.font = "14px system-ui";
        ctx.fillText(info, canvas.width - tw, 24);
      }
      async function tickOnce() {
        let dets = [];
        if (mode === "parallel") {
          let serverDets = [];
          let localDets = [];
          try {
            setStatus("服务端识别中");
            serverDets = await detectServer();
            setStatus(`服务端识别成功（${serverDets.length}）`);
          } catch (e) {
            serverDets = [];
          }
          try {
            if (!model) {
              await ensureCoco();
              model = await cocoSsd.load();
            }
            setStatus("本地模型识别中");
            localDets = await model.detect(video);
            setStatus(`本地识别成功（${localDets.length}）`);
          } catch (e) {
            localDets = [];
          }
          const key = (d) =>
            `${d.label || d.class || "物体"}@${(d.bbox || []).join(",")}`;
          const map = new Map();
          for (const d of [...serverDets, ...localDets]) {
            map.set(key(d), d);
          }
          dets = Array.from(map.values());
          lastDets = dets;
          speakDetections(dets, "merged");
          return;
        } else if (mode === "server") {
          try {
            setStatus("服务端识别中");
            dets = await detectServer();
            setStatus(`服务端识别成功（${dets.length}）`);
            lastDets = dets;
            speakDetections(dets, "server");
            return;
          } catch (e) {
            try {
              if (!model) {
                await ensureCoco();
                model = await cocoSsd.load();
              }
              setStatus("本地模型识别中");
              dets = await model.detect(video);
              setStatus(`本地识别成功（${dets.length}）`);
            } catch {
              setStatus("识别失败");
              dets = [];
            }
            lastDets = dets;
            speakDetections(dets, "local");
            return;
          }
        } else {
          try {
            if (!model) {
              await ensureCoco();
              model = await cocoSsd.load();
            }
            setStatus("本地模型识别中");
            dets = await model.detect(video);
            setStatus(`本地识别成功（${dets.length}）`);
            lastDets = dets;
            speakDetections(dets, "local");
            return;
          } catch (e) {
            try {
              setStatus("服务端识别中");
              dets = await detectServer();
              setStatus(`服务端识别成功（${dets.length}）`);
            } catch {
              setStatus("识别失败");
              dets = [];
            }
            lastDets = dets;
            speakDetections(dets, "server");
            return;
          }
        }
      }
      async function loop() {
        if (!running) return;
        const now = performance.now();
        const interval = Math.max(125, Math.floor(1000 / Number(fps)));
        if (now - lastMs >= interval) {
          lastMs = now;
          await tickOnce();
        }
        await drawFrame();
        drawOverlay(lastDets || []);
        raf = requestAnimationFrame(loop);
      }
      async function start() {
        if (!window.isSecureContext) {
          alert(
            "当前为非安全上下文，摄像头被阻止。请使用 https 或 localhost。"
          );
          return;
        }
        try {
          let stream;
          try {
            stream = await navigator.mediaDevices.getUserMedia({
              video: {
                facingMode: "environment",
                width: { ideal: 1920 },
                height: { ideal: 1080 },
                advanced: [{ torch: true }],
              },
              audio: false,
            });
          } catch {
            stream = await navigator.mediaDevices.getUserMedia({
              video: {
                width: { ideal: 1280 },
                height: { ideal: 720 },
              },
              audio: false,
            });
          }
          video.srcObject = stream;
          try {
            const track = stream.getVideoTracks()[0];
            if (track) imageCapture = new ImageCapture(track);
          } catch {}
          await new Promise((resolve) => {
            video.onloadedmetadata = () => resolve();
          });
          try {
            await video.play();
          } catch {}
          await ensureVideoReady(video);
          const w = video.videoWidth || 1280;
          const h = video.videoHeight || 720;
          canvas.width = w;
          canvas.height = h;
          captureCanvas.width = w;
          captureCanvas.height = h;
          setRunning(true);
          setStatus("已启动");
          try {
            const utter = new SpeechSynthesisUtterance("识别已启动");
            utter.lang = "zh-CN";
            utter.rate = 1;
            speechSynthesis.speak(utter);
          } catch {}
          await tickOnce();
          loop();
        } catch (e) {
          alert(`无法启动摄像头：${e?.name || ""} ${e?.message || ""}`);
        }
      }
      function stop() {
        setRunning(false);
        if (raf) cancelAnimationFrame(raf);
        const tracks = video.srcObject ? video.srcObject.getTracks() : [];
        tracks.forEach((t) => t.stop());
        video.srcObject = null;
      }
      function onResize() {
        if (video && video.videoWidth) {
          const w = video.videoWidth || 1280;
          const h = video.videoHeight || 720;
          canvas.width = w;
          canvas.height = h;
        }
      }
      startBtn.addEventListener("click", start);
      stopBtn.addEventListener("click", stop);
      speakToggle.addEventListener("change", (e) => {
        speakOn = e.target.checked;
      });
      fpsSelect.addEventListener("change", (e) => {
        fps = Number(e.target.value);
      });
      modeSelect.addEventListener("change", (e) => {
        mode = e.target.value;
      });
      window.addEventListener("resize", onResize);
    </script>
    <div id="root"></div>
    <script type="text/babel">
      function App() {
        return null;
      }
      const root = ReactDOM.createRoot(document.getElementById("root"));
      root.render(<App />);
    </script>
  </body>
</html>
